#!/usr/bin/env python3
"""
Graph Analyzer for Tycho Searcher
Reads and analyzes the largest_component.json graph file generated by tycho-searcher.
Performs basic graph statistics and visualizations.
"""

import json
import sys
import os
from pathlib import Path
from collections import defaultdict, Counter
import argparse
import re

# Optional imports for visualization (install with: pip install matplotlib networkx pandas)
try:
    import matplotlib.pyplot as plt
    import networkx as nx
    import pandas as pd
    HAS_VIZ = True
except ImportError:
    print("Warning: matplotlib, networkx, or pandas not found. Visualization disabled.")
    print("Install with: pip install matplotlib networkx pandas")
    HAS_VIZ = False


def load_graph(file_path):
    """Load graph from JSON file."""
    try:
        with open(file_path, 'r') as f:
            data = json.load(f)
        return data
    except FileNotFoundError:
        print(f"Error: File {file_path} not found.")
        print("Run tycho-searcher with --export-graph flag to generate the file.")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON: {e}")
        sys.exit(1)


def analyze_basic_stats(graph_data):
    """Perform basic graph statistics."""
    nodes = graph_data.get('nodes', [])
    edges = graph_data.get('edges', [])
    
    print("=== Basic Graph Statistics ===")
    print(f"Total nodes (tokens): {len(nodes)}")
    print(f"Total edges (pools): {len(edges)}")
    print(f"Block number: {graph_data.get('block_number', 'N/A')}")
    
    # Debug: Show structure of first node and edge
    if nodes:
        print(f"\nDebug: First node keys: {list(nodes[0].keys())}")
        if 'token' in nodes[0]:
            print(f"Debug: First node token keys: {list(nodes[0]['token'].keys()) if nodes[0]['token'] else 'None'}")
    
    if edges:
        print(f"Debug: First edge keys: {list(edges[0].keys())}")
        if 'pool' in edges[0]:
            print(f"Debug: First edge pool keys: {list(edges[0]['pool'].keys()) if edges[0]['pool'] else 'None'}")
    
    # Token analysis
    token_symbols = []
    for node in nodes:
        token_data = node.get('token', {})
        symbol = token_data.get('symbol', node.get('symbol', 'Unknown'))
        token_symbols.append(symbol)
    
    token_counts = Counter(token_symbols)
    
    print(f"\n=== Token Distribution ===")
    print(f"Unique token symbols: {len(set(token_symbols))}")
    
    # Most common tokens
    print("\nTop 10 most connected tokens:")
    for symbol, count in token_counts.most_common(10):
        print(f"  {symbol}: {count} occurrences")
    
    return nodes, edges


def analyze_pools(edges):
    """Analyze pool statistics."""
    print("\n=== Pool Analysis ===")
    
    # Pool types from protocol_system
    pool_types = []
    for edge in edges:
        pool_data = edge.get('pool', {})
        protocol_system = pool_data.get('protocol_system', edge.get('pool_type', 'Unknown'))
        pool_types.append(protocol_system)
    
    type_counts = Counter(pool_types)
    
    print("Pool protocol distribution:")
    for pool_type, count in type_counts.items():
        print(f"  {pool_type}: {count} pools")
    
    # TVL analysis
    tvls = []
    for edge in edges:
        tvl = edge.get('tvl', 0)
        if isinstance(tvl, (int, float)) and tvl > 0:
            tvls.append(tvl)
    
    if tvls:
        print(f"\n=== TVL Statistics ===")
        print(f"Pools with TVL data: {len(tvls)}")
        print(f"Total TVL: ${sum(tvls):,.2f}")
        print(f"Average TVL: ${sum(tvls)/len(tvls):,.2f}")
        print(f"Median TVL: ${sorted(tvls)[len(tvls)//2]:,.2f}")
        print(f"Max TVL: ${max(tvls):,.2f}")
        print(f"Min TVL: ${min(tvls):,.2f}")


def analyze_connectivity(nodes, edges):
    """Analyze graph connectivity."""
    print("\n=== Connectivity Analysis ===")
    
    # Build adjacency information
    node_degrees = defaultdict(int)
    node_id_to_symbol = {}
    
    # Map node IDs to symbols with validation, using token.symbol
    for i, node in enumerate(nodes):
        node_id = node.get('id')
        if node_id is None:
            node_id = f"node_{i}"  # Use same fallback as in create_networkx_graph
        
        # Get symbol from token data structure
        token_data = node.get('token', {})
        symbol = token_data.get('symbol', node.get('symbol', 'Unknown'))
        node_id_to_symbol[node_id] = symbol
    
    # Count degrees with validation
    for edge in edges:
        from_id = edge.get('from')
        to_id = edge.get('to')
        
        # Skip edges with missing endpoints
        if from_id is None or to_id is None:
            continue
            
        node_degrees[from_id] += 1  # out-degree
        node_degrees[to_id] += 1    # in-degree (treating as undirected for simplicity)
    
    # Most connected tokens
    degree_list = [(node_id_to_symbol.get(node_id, f"ID:{node_id}"), degree) 
                   for node_id, degree in node_degrees.items()]
    degree_list.sort(key=lambda x: x[1], reverse=True)
    
    print("Top 10 most connected tokens:")
    for symbol, degree in degree_list[:10]:
        print(f"  {symbol}: {degree} connections")
    
    # Degree distribution
    degrees = list(node_degrees.values())
    if degrees:
        print(f"\n=== Degree Statistics ===")
        print(f"Average degree: {sum(degrees)/len(degrees):.2f}")
        print(f"Max degree: {max(degrees)}")
        print(f"Min degree: {min(degrees)}")
    else:
        print("No valid edges found for degree analysis")


def create_networkx_graph(nodes, edges):
    """Create NetworkX graph for analysis and visualization."""
    if not HAS_VIZ:
        return None

    # Use an undirected graph view for visualization clarity (no arrowheads)
    G = nx.Graph()
    
    # Add nodes with validation, using node 'index' as the canonical integer ID
    valid_node_ids = set()
    for i, node in enumerate(nodes):
        # Prefer explicit integer 'index' if present (common in exported graphs)
        node_index = node.get('index')
        node_id_field = node.get('id')

        # Determine canonical numeric node id (prefer index, fallback to id)
        canonical_id = None
        if node_index is not None:
            try:
                canonical_id = int(node_index)
            except Exception:
                canonical_id = node_index
        elif node_id_field is not None:
            # Try to coerce to int if possible
            try:
                canonical_id = int(node_id_field)
            except Exception:
                canonical_id = node_id_field
        else:
            canonical_id = f"node_{i}"
            print(f"Warning: Node without ID or index found, using fallback: {canonical_id}")

        # Get symbol from token data structure
        token_data = node.get('token', {})
        symbol = token_data.get('symbol', node.get('symbol', 'Unknown'))

        try:
            # Create a copy of node data without potential problematic keys
            node_data = {k: v for k, v in node.items() if v is not None and k not in ('id', 'index')}
            G.add_node(canonical_id, symbol=symbol, **node_data)
            valid_node_ids.add(canonical_id)
        except Exception as e:
            print(f"Warning: Failed to add node {canonical_id}: {e}")

    # Debug sample of node id space
    sorted_ids = sorted(list(valid_node_ids), key=lambda x: (isinstance(x, int), x))
    print(f"Debug: Valid node IDs (first 10): {sorted_ids[:10]}")
    print(f"Debug: Valid node IDs (last 10): {sorted_ids[-10:]}")
    print(f"Debug: Total valid nodes: {len(valid_node_ids)}")
    
    # Add edges with validation, extracting protocol from pool data
    edges_added = 0
    edges_skipped = 0
    for edge in edges:
        # Try both field name patterns: 'from'/'to' and 'source'/'target'
        raw_from = edge.get('from') if 'from' in edge else edge.get('source')
        raw_to = edge.get('to') if 'to' in edge else edge.get('target')

        # Coerce endpoint IDs to the same type used for nodes (prefer ints)
        def coerce_id(x):
            if x is None:
                return None
            try:
                return int(x)
            except Exception:
                return x

        from_id = coerce_id(raw_from)
        to_id = coerce_id(raw_to)
        
        # Debug: Print first few edges to understand structure
        if edges_added < 3 and edges_skipped < 10:
            print(f"Debug: Edge structure: {list(edge.keys())}")
            print(f"Debug: from={from_id}, to={to_id} (using source/target fields)")
            print(f"Debug: from_id in valid_nodes: {from_id in valid_node_ids}")
            print(f"Debug: to_id in valid_nodes: {to_id in valid_node_ids}")
            if 'pool' in edge:
                print(f"Debug: pool keys: {list(edge['pool'].keys()) if edge['pool'] else 'None'}")
        
        # Skip edges with missing endpoints
        if from_id is None or to_id is None:
            edges_skipped += 1
            continue
            print(f"Debug: Edge structure: {list(edge.keys())}")
            print(f"Debug: from={from_id}, to={to_id} (using source/target fields)")
            if 'pool' in edge:
                print(f"Debug: pool keys: {list(edge['pool'].keys()) if edge['pool'] else 'None'}")
        
        # Skip edges with missing endpoints
        if from_id is None or to_id is None:
            edges_skipped += 1
            continue
            
        # Only add edges between valid nodes
        if from_id in valid_node_ids and to_id in valid_node_ids:
            try:
                # Extract protocol system from pool data
                pool_data = edge.get('pool', {})
                protocol_system = pool_data.get('protocol_system', edge.get('pool_type', 'Unknown'))
                
                # Create a copy of edge data without potential problematic keys
                edge_data = {k: v for k, v in edge.items() if v is not None and k not in ['from', 'to']}
                edge_data['protocol_system'] = protocol_system
                G.add_edge(from_id, to_id, **edge_data)
                edges_added += 1
            except Exception as e:
                print(f"Warning: Failed to add edge {from_id} -> {to_id}: {e}")
                edges_skipped += 1
        else:
            edges_skipped += 1
    
    print(f"Created NetworkX graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges")
    print(f"Edges added: {edges_added}, skipped: {edges_skipped}")
    if edges_skipped > 0:
        print(f"Debug: Total edges in JSON: {len(edges)}, valid node IDs: {len(valid_node_ids)}")
    return G




def apply_sceleton(G):
    """Apply skeletal pruning to the graph in-place.

    - Remove self-loops.
    - Iteratively remove leaves (degree 1 nodes) until none remain.
    - Collapse degree-2 nodes by connecting their neighbors with a special attribute
      and removing the degree-2 node.

    Returns a dict of statistics about the modifications.
    """
    removed_loops = 0
    removed_leaves = 0
    collapsed = 0

    # Work on a copy of G's node list to avoid runtime mutation issues
    # 1) Remove self-loops
    self_loops = list(nx.selfloop_edges(G))
    for u, v in self_loops:
        try:
            G.remove_edge(u, v)
            removed_loops += 1
        except Exception:
            pass

    # Iteratively remove leaves and collapse degree-2 nodes until stable
    changed = True
    while changed:
        changed = False

        # Remove leaves and isolated nodes
        leaves = [n for n, d in G.degree() if d <= 1]
        if leaves:
            for n in leaves:
                try:
                    G.remove_node(n)
                    removed_leaves += 1
                    changed = True
                except Exception:
                    pass

        # Collapse degree-2 nodes
        degree_two_nodes = [n for n, d in G.degree() if d == 2]
        if degree_two_nodes:
            for n in degree_two_nodes:
                try:
                    # If node was removed in a previous step, skip
                    if n not in G:
                        continue
                    nbrs = list(G.neighbors(n))
                    if len(nbrs) != 2:
                        continue
                    a, b = nbrs
                    # avoid creating self-loop
                    if a == b:
                        # removing the node will remove the loop effectively
                        G.remove_node(n)
                        removed_leaves += 1
                        changed = True
                        continue
                    # Gather attributes from edges (if any) and set a collapsed marker
                    edge_attrs = {}
                    if G.has_edge(a, n):
                        edge_attrs.update(G.get_edge_data(a, n) or {})
                    if G.has_edge(n, b):
                        edge_attrs.update(G.get_edge_data(n, b) or {})
                    # Mark the collapsed edge as skeletal (dashed)
                    edge_attrs['sceleton'] = True
                    # If an edge already exists between a and b, merge attributes conservatively
                    if G.has_edge(a, b):
                        existing = G.get_edge_data(a, b) or {}
                        existing.update(edge_attrs)
                        G[a][b].update(existing)
                    else:
                        G.add_edge(a, b, **edge_attrs)
                    # Finally remove the degree-2 node
                    if n in G:
                        G.remove_node(n)
                        collapsed += 1
                        changed = True
                except Exception:
                    continue

    return {'removed_loops': removed_loops, 'removed_leaves': removed_leaves, 'collapsed': collapsed}

def visualize_graph(G, output_dir="tools/plots"):
    """Create visualizations of the graph."""
    if not HAS_VIZ or G is None:
        print("Skipping visualization (missing dependencies)")
        return
        
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\n=== Creating Visualizations ===")
    print(f"Saving plots to: {output_dir}/")
    
    # 1. Degree distribution
    degrees = [G.degree(n) for n in G.nodes()]
    if degrees:
        plt.figure(figsize=(10, 6))
        plt.hist(degrees, bins=min(50, len(set(degrees))), alpha=0.7, edgecolor='black')
        plt.xlabel('Node Degree')
        plt.ylabel('Frequency')
        plt.title('Token Connectivity Distribution')
        plt.yscale('log')
        plt.grid(True, alpha=0.3)
        plt.show()
        print("  Degree distribution displayed")
    else:
        print("  No nodes found, skipping degree distribution plot")
    
    # 2. TVL distribution
    tvls = []
    for _, _, data in G.edges(data=True):
        tvl = data.get('tvl', 0)
        if isinstance(tvl, (int, float)) and tvl > 0:
            tvls.append(tvl)
    
    if tvls:
        plt.figure(figsize=(10, 6))
        plt.hist(tvls, bins=50, alpha=0.7, edgecolor='black')
        plt.xlabel('Pool TVL ($)')
        plt.ylabel('Frequency')
        plt.title('Pool TVL Distribution')
        plt.xscale('log')
        plt.yscale('log')
        plt.grid(True, alpha=0.3)
        plt.show()
        print("  TVL distribution displayed")
    
    # 3. Pool protocol distribution (updated to use protocol_system)
    pool_protocols = []
    for _, _, data in G.edges(data=True):
        protocol = data.get('protocol_system', data.get('pool_type', 'Unknown'))
        pool_protocols.append(protocol)
    
    if pool_protocols:
        protocol_counts = Counter(pool_protocols)
        plt.figure(figsize=(12, 6))
        protocols, counts = zip(*protocol_counts.most_common())
        plt.bar(protocols, counts, alpha=0.7, edgecolor='black')
        plt.xlabel('Protocol System')
        plt.ylabel('Count')
        plt.title('Protocol System Distribution')
        plt.xticks(rotation=45, ha='right')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
        print("  Protocol distribution displayed")
    else:
        print("  No protocol data found, skipping protocol plot")
    
    # 4. Enhanced graph layout with colored edges by protocol
    if G.number_of_nodes() <= 500:
        plt.figure(figsize=(14, 10))

        # Use a force-directed layout but allow NetworkX to tune spacing
        try:
            pos = nx.spring_layout(G, k=None, iterations=200)
        except Exception:
            pos = nx.spring_layout(G)

        # Create node labels using token symbols (strings)
        node_labels = {}
        for node in G.nodes():
            token_data = G.nodes[node].get('token', {})
            # Prefer symbol, fall back to a short string id
            sym = token_data.get('symbol') if isinstance(token_data, dict) else None
            if not sym:
                sym = G.nodes[node].get('symbol', str(node))
            node_labels[node] = str(sym)

        # Node sizes proportional to degree (min 100, max 2000)
        degrees = dict(G.degree())
        node_sizes = []
        for n in G.nodes():
            d = degrees.get(n, 1)
            size = min(2000, max(100, 50 + d * 50))
            node_sizes.append(size)

        # Color edges by protocol system
        protocol_colors = {}
        protocols = set()
        for _, _, data in G.edges(data=True):
            protocol = data.get('protocol_system', 'Unknown')
            protocols.add(protocol)

        # Build a color map for protocols
        from matplotlib import cm
        cmap = cm.get_cmap('tab10')
        for i, protocol in enumerate(sorted(protocols)):
            protocol_colors[protocol] = cmap(i % cmap.N)

        # Draw nodes
        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='lightblue', alpha=0.9)

        # Draw edges grouped by protocol (no arrows)
        # Separate skeleton (collapsed) edges from normal edges
        skeleton_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('sceleton')]
        normal_edges = [(u, v, d) for u, v, d in G.edges(data=True) if not d.get('sceleton')]

        # Draw normal edges grouped by protocol
        for protocol in sorted(protocols):
            edges_of_protocol = [(u, v) for u, v, d in normal_edges
                                 if d.get('protocol_system', 'Unknown') == protocol]
            if edges_of_protocol:
                nx.draw_networkx_edges(G, pos, edgelist=edges_of_protocol,
                                       edge_color=protocol_colors[protocol],
                                       alpha=0.6)

        # Draw skeleton edges dashed and gray
        if skeleton_edges:
            nx.draw_networkx_edges(G, pos, edgelist=skeleton_edges, style='dashed',
                                   edge_color='gray', alpha=0.6)

        # Draw labels as strings
        nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)

        # Add legend for protocols
        if protocols:
            for protocol in sorted(protocols):
                plt.plot([], [], color=protocol_colors[protocol], label=protocol)
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

        plt.title('Token Trading Graph (undirected, protocol-colored edges)')
        plt.axis('off')
        plt.tight_layout()
        plt.show()
        print(f"  Enhanced undirected graph layout displayed (nodes: {G.number_of_nodes()}, edges: {G.number_of_edges()})")
    else:
        print(f"  Skipping graph layout (too many nodes: {G.number_of_nodes()})")
    
    if tvls:
        print("  TVL distribution displayed")
    else:
        print("  No TVL data found, skipped TVL distribution plot")


def main():
    parser = argparse.ArgumentParser(description='Analyze Tycho Searcher graph data')
    parser.add_argument('--file', '-f', default='largest_component.json',
                       help='JSON file to analyze (default: largest_component.json)')
    parser.add_argument('--no-viz', action='store_true',
                       help='Skip visualization generation')
    parser.add_argument('--sceleton', action='store_true',
                       help='Apply skeletal pruning: remove self-loops, iteratively delete leaves, collapse degree-2 nodes into dashed edges')
    parser.add_argument('--latex', nargs='?', const='graph.tex', default=None,
                       help='Export graph as a TikZ diagram to the given file (default: graph.tex when flag used without value)')
    parser.add_argument('--output-dir', '-o', default='tools/plots',
                       help='Output directory for plots (default: tools/plots)')
    
    args = parser.parse_args()
    
    # Check if file exists, try different locations
    file_candidates = [
        args.file,
        f"../{args.file}",
        f"../../{args.file}",
        f"/Users/Shared/tycho-searcher/{args.file}"
    ]
    
    graph_file = None
    for candidate in file_candidates:
        if os.path.exists(candidate):
            graph_file = candidate
            break
    
    if not graph_file:
        print(f"Error: Could not find {args.file}")
        print("Tried locations:", file_candidates)
        print("\nRun tycho-searcher with --export-graph flag to generate the file.")
        sys.exit(1)
    
    print(f"Loading graph from: {graph_file}")
    graph_data = load_graph(graph_file)
    
    # Perform analysis
    nodes, edges = analyze_basic_stats(graph_data)
    analyze_pools(edges)
    analyze_connectivity(nodes, edges)
    
    # Create visualizations
    if not args.no_viz and HAS_VIZ:
        G = create_networkx_graph(nodes, edges)
        if args.sceleton:
            print("Applying skeletal pruning (--sceleton) to graph...")
            stats = apply_sceleton(G)
            print(f"  Removed loops: {stats.get('removed_loops',0)}, removed leaves: {stats.get('removed_leaves',0)}, collapsed degree-2 nodes: {stats.get('collapsed',0)}")
        visualize_graph(G, args.output_dir)
        # If LaTeX export requested, compute positions and write TikZ file
        if args.latex:
            tikz_file = args.latex if isinstance(args.latex, str) else 'graph.tex'
            print(f"Exporting TikZ to: {tikz_file}")
            try:
                pos = nx.spring_layout(G, k=None, iterations=200)
            except Exception:
                pos = nx.spring_layout(G)
            export_tikz(G, pos, tikz_file)
    elif not HAS_VIZ:
        print("\nTo enable visualizations, install: pip install matplotlib networkx pandas")
    
    print("\n=== Analysis Complete ===")


def export_tikz(G, pos, file_path):
    """Export the current graph to a TikZ/PGF picture in a standalone TeX file.

    - `G` is a NetworkX Graph with node labels in `symbol` or token.symbol
    - `pos` is a dict mapping node -> (x, y) as produced by `spring_layout`
    This function writes a minimal standalone LaTeX file using TikZ.
    """
    # Map protocols to simple colors (hex)
    protocol_set = set()
    for _, _, d in G.edges(data=True):
        protocol_set.add(d.get('protocol_system', 'Unknown'))
    protocols = sorted(protocol_set)
    color_palette = ["FF0000", "0000FF", "00AA00", "FF7700", "9900CC", "8B4513", "FF69B4", "808080", "808000", "00FFFF"]
    protocol_colors = {p: color_palette[i % len(color_palette)] for i, p in enumerate(protocols)}

    # Normalize positions into a reasonable bounding box
    xs = [xy[0] for xy in pos.values()]
    ys = [xy[1] for xy in pos.values()]
    minx, maxx = min(xs), max(xs)
    miny, maxy = min(ys), max(ys)
    dx = maxx - minx if maxx != minx else 1.0
    dy = maxy - miny if maxy != miny else 1.0

    def to_page(xy):
        x, y = xy
        # map to cm coordinates in [-8,8] x [-6,6]
        px = -8 + 16 * ((x - minx) / dx)
        py = -6 + 12 * ((y - miny) / dy)
        return px, py

    # Create sanitized protocol color names and print color definitions to stdout
    def sanitize_protocol_name(proto: str) -> str:
        # Use last colon-separated segment, lowercase, replace non-alnum with underscore
        last_seg = proto.split(':')[-1]
        s = last_seg.lower()
        s = re.sub(r"[^0-9a-zA-Z]+", "_", s)
        s = s.strip('_')
        if not s:
            s = 'unknown'
        return f'prot_{s}'

    protocol_name_map = {}
    used_names = {}
    for p in protocols:
        base = sanitize_protocol_name(p)
        name = base
        # Ensure uniqueness
        if name in used_names:
            used_names[name] += 1
            name = f"{base}_{used_names[name]}"
        else:
            used_names[name] = 0
        protocol_name_map[p] = name

    # Print color definitions to stdout (user requested)
    for p in protocols:
        hexcol = protocol_colors[p]
        cname = protocol_name_map.get(p, 'black')
        print(f"\\definecolor{{{cname}}}{{HTML}}{{{hexcol}}}  % protocol: {p}")

    # Start writing file with xcolor in preamble
    with open(file_path, 'w') as f:
        f.write('%!TEX root = ../searcher_documentation.tex\n')
        f.write('\\begin{tikzpicture}[>=stealth, scale=1]\n')

        
        # Draw nodes
        for n in G.nodes():
            p = to_page(pos[n])
            token_data = G.nodes[n].get('token', {})
            sym = token_data.get('symbol') if isinstance(token_data, dict) else None
            if not sym:
                sym = G.nodes[n].get('symbol', str(n))
            label = str(sym)
            #f.write('  \\filldraw[fill=white, draw=black] (%.3fcm, %.3fcm) circle (0.20cm);\n' % (p[0], p[1]))
            # Node label slightly offset
            f.write('  \\node[tokenstyle] (%s) at (%.3fcm, %.3fcm) {%s};\n' % (label.replace('_', ''), p[0] + 0.25, p[1] - 0.07, label.replace('_', '\\_')))

        # Draw edges: first normal edges (group by protocol)
        for u, v, d in G.edges(data=True):
            protocol = d.get('protocol_system', 'Unknown')
            style = 'dashed' if d.get('sceleton') else 'solid'
            color_name = protocol_name_map.get(protocol, 'black')
            f.write('  \\draw[draw=%s, %s] (%s) -- (%s);\n' % (color_name, style, G.nodes[u].get('symbol', str(u)).replace('_', ''), G.nodes[v].get('symbol', str(v)).replace('_', '')))

        # Legend for protocols (simple boxes)
        lx = -8
        ly = 6.5
        f.write('  % Legend\n')
        for i, p in enumerate(protocols):
            cname = protocol_name_map.get(p, f'prot_{i}')
            f.write('  \\draw[draw=%s, fill=%s] (%.2fcm, %.2fcm) rectangle (%.2fcm, %.2fcm); \\node[anchor=west] at (%.2fcm, %.2fcm) {\\small %s};\n' % (
                cname, cname, lx, ly - i * 0.4, lx + 0.3, ly - 0.25 - i * 0.4, lx + 0.35, ly - i * 0.4, p.replace('_', '\\_')
            ))

        f.write('\\end{tikzpicture}\n')

    print(f"TikZ exported to {file_path}")

if __name__ == "__main__":
    main()